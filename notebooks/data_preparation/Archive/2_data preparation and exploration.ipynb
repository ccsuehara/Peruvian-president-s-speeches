{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "This notebook reads the `TXT` files of the speeches and builds a single dataframe with every tokenized and normalized content we'll use.\n",
    "\n",
    "Please note that none of the code chunks of this notebook were actually ran from here. As the processing part took a great amount of time to be completed, we transformed this notebook in a `Python` script and submitted it through the slurm work manager of the Computer Science department. The script is the file `2_data_preparation.py` in this same directory, and the file `run_data_preparation.sbatch` loads it to the slurm environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from nltk.tokenize import sent_tokenize\n",
    "#from lucem_illud_2020 import word_tokenize\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../../scripts')\n",
    "import data_cleaning as clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the directory of the speeches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_dir = '../../../data/presidentialSpeechPeru/txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus from this path using a helper function we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mensaje-1956-mpu.txt\n",
      "mensaje-1957-mpu.txt\n",
      "mensaje-1958-mpu.txt\n",
      "mensaje-1959-mpu.txt\n",
      "mensaje-1960-mpu.txt\n",
      "mensaje-1961-mpu.txt\n",
      "mensaje-1962-nll.txt\n",
      "mensaje-1963-fbt.txt\n",
      "mensaje-1964-fbt.txt\n",
      "mensaje-1965-fbt.txt\n",
      "mensaje-1966-fbt.txt\n",
      "mensaje-1967-fbt.txt\n",
      "mensaje-1968-fbt.txt\n",
      "mensaje-1969-jva.txt\n",
      "mensaje-1970-jva.txt\n",
      "mensaje-1971-jva.txt\n",
      "mensaje-1972-jva.txt\n",
      "mensaje-1973-jva.txt\n",
      "mensaje-1974-jva.txt\n",
      "mensaje-1975-jva.txt\n",
      "mensaje-1976-fmb.txt\n",
      "mensaje-1977-fmb.txt\n",
      "mensaje-1978-fmb.txt\n",
      "mensaje-1979-fmb.txt\n",
      "mensaje-1980-fbt.txt\n",
      "mensaje-1981-fbt.txt\n",
      "mensaje-1982-fbt.txt\n",
      "mensaje-1983-fbt.txt\n",
      "mensaje-1984-fbt.txt\n",
      "mensaje-1985-ag.txt\n",
      "mensaje-1986-ag.txt\n",
      "mensaje-1987-ag.txt\n",
      "mensaje-1988-ag.txt\n",
      "mensaje-1989-ag.txt\n",
      "mensaje-1990-af.txt\n",
      "mensaje-1991-af.txt\n",
      "mensaje-1992-af.txt\n",
      "mensaje-1993-af.txt\n",
      "mensaje-1994-af.txt\n",
      "mensaje-1995-af.txt\n",
      "mensaje-1996-af.txt\n",
      "mensaje-1997-af.txt\n",
      "mensaje-1998-af.txt\n",
      "mensaje-1999-af.txt\n",
      "mensaje-2000-af.txt\n",
      "mensaje-2000-vp-noviembre.txt\n",
      "mensaje-2001-at.txt\n",
      "mensaje-2002-at.txt\n",
      "mensaje-2003-at.txt\n",
      "mensaje-2004-at.txt\n",
      "mensaje-2005-at.txt\n",
      "mensaje-2006-ag.txt\n",
      "mensaje-2007-ag.txt\n",
      "mensaje-2008-ag.txt\n",
      "mensaje-2009-ag.txt\n",
      "mensaje-2010-ag.txt\n",
      "mensaje-2011-oh.txt\n",
      "mensaje-2012-oh.txt\n",
      "mensaje-2013-oh.txt\n",
      "mensaje-2014-oh.txt\n",
      "mensaje-2015-oh.txt\n",
      "mensaje-2016-ppk.txt\n",
      "mensaje-2017-ppk.txt\n",
      "mensaje-2018-2.txt\n",
      "mensaje-2018-4.txt\n",
      "mensaje-2019-01-vizcarra.txt\n",
      "mensaje-2020-fsh.txt\n"
     ]
    }
   ],
   "source": [
    "speeches_raw = clean.loadcorpus(speeches_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we load the result in a data frame and start adding some metadata columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mensaje-1956-mpu.txt\n",
      "mensaje-1957-mpu.txt\n",
      "mensaje-1958-mpu.txt\n",
      "mensaje-1959-mpu.txt\n",
      "mensaje-1960-mpu.txt\n",
      "mensaje-1961-mpu.txt\n",
      "mensaje-1962-nll.txt\n",
      "mensaje-1963-fbt.txt\n",
      "mensaje-1964-fbt.txt\n",
      "mensaje-1965-fbt.txt\n",
      "mensaje-1966-fbt.txt\n",
      "mensaje-1967-fbt.txt\n",
      "mensaje-1968-fbt.txt\n",
      "mensaje-1969-jva.txt\n",
      "mensaje-1970-jva.txt\n",
      "mensaje-1971-jva.txt\n",
      "mensaje-1972-jva.txt\n",
      "mensaje-1973-jva.txt\n",
      "mensaje-1974-jva.txt\n",
      "mensaje-1975-jva.txt\n",
      "mensaje-1976-fmb.txt\n",
      "mensaje-1977-fmb.txt\n",
      "mensaje-1978-fmb.txt\n",
      "mensaje-1979-fmb.txt\n",
      "mensaje-1980-fbt.txt\n",
      "mensaje-1981-fbt.txt\n",
      "mensaje-1982-fbt.txt\n",
      "mensaje-1983-fbt.txt\n",
      "mensaje-1984-fbt.txt\n",
      "mensaje-1985-ag.txt\n",
      "mensaje-1986-ag.txt\n",
      "mensaje-1987-ag.txt\n",
      "mensaje-1988-ag.txt\n",
      "mensaje-1989-ag.txt\n",
      "mensaje-1990-af.txt\n",
      "mensaje-1991-af.txt\n",
      "mensaje-1992-af.txt\n",
      "mensaje-1993-af.txt\n",
      "mensaje-1994-af.txt\n",
      "mensaje-1995-af.txt\n",
      "mensaje-1996-af.txt\n",
      "mensaje-1997-af.txt\n",
      "mensaje-1998-af.txt\n",
      "mensaje-1999-af.txt\n",
      "mensaje-2000-af.txt\n",
      "mensaje-2000-vp-noviembre.txt\n",
      "mensaje-2001-at.txt\n",
      "mensaje-2002-at.txt\n",
      "mensaje-2003-at.txt\n",
      "mensaje-2004-at.txt\n",
      "mensaje-2005-at.txt\n",
      "mensaje-2006-ag.txt\n",
      "mensaje-2007-ag.txt\n",
      "mensaje-2008-ag.txt\n",
      "mensaje-2009-ag.txt\n",
      "mensaje-2010-ag.txt\n",
      "mensaje-2011-oh.txt\n",
      "mensaje-2012-oh.txt\n",
      "mensaje-2013-oh.txt\n",
      "mensaje-2014-oh.txt\n",
      "mensaje-2015-oh.txt\n",
      "mensaje-2016-ppk.txt\n",
      "mensaje-2017-ppk.txt\n",
      "mensaje-2018-2.txt\n",
      "mensaje-2018-4.txt\n",
      "mensaje-2019-01-vizcarra.txt\n",
      "mensaje-2020-fsh.txt\n"
     ]
    }
   ],
   "source": [
    "speech = pd.DataFrame()\n",
    "filenames = []\n",
    "raw = []\n",
    "for filename, raw_speech in speeches_raw.items():\n",
    "    print(filename)\n",
    "    filenames.append(filename)\n",
    "    raw.append(raw_speech)\n",
    "speech['filename'] = filenames\n",
    "speech['raw text'] = raw\n",
    "\n",
    "pattern = re.compile('[0-9]{4}')\n",
    "speech['year'] = speech['filename'].apply(lambda x: pattern.search(x).group(0))\n",
    "speech = speech.sort_values(by='year').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we clean these raw texts using another ad-hoc function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech['cleaned text'] = speech['raw text'].apply(lambda x: clean.clean_raw_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the administration and president of each speech:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech.loc[(speech['year'].astype('int32') >= 1956) & \\\n",
    "           (speech['year'].astype('int32') <= 1961), 'administration'] = 'Prado'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1962) & \\\n",
    "           (speech['year'].astype('int32') <= 1962), 'administration'] = 'Lindley'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1963) & \\\n",
    "           (speech['year'].astype('int32') <= 1968), 'administration'] = 'Belaunde(1)'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1969) & \\\n",
    "           (speech['year'].astype('int32') <= 1975), 'administration'] = 'Velasco'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1976) & \\\n",
    "           (speech['year'].astype('int32') <= 1979), 'administration'] = 'Morales Bermudez'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1980) & \\\n",
    "           (speech['year'].astype('int32') <= 1984), 'administration'] = 'Belaunde(2)'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1985) & \\\n",
    "           (speech['year'].astype('int32') <= 1989), 'administration'] = 'Garcia(1)'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1990) & \\\n",
    "           (speech['year'].astype('int32') <= 1994), 'administration'] = 'Fujimori(1)'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1995) & \\\n",
    "           (speech['year'].astype('int32') <= 2000), 'administration'] = 'Fujimori(2)'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2001) & \\\n",
    "           (speech['year'].astype('int32') <= 2005), 'administration'] = 'Toledo'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2006) & \\\n",
    "           (speech['year'].astype('int32') <= 2010), 'administration'] = 'Garcia(2)'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2011) & \\\n",
    "           (speech['year'].astype('int32') <= 2015), 'administration'] = 'Humala'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2016), 'administration'] = 'Kuzcynski/Vizcarra'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1956) & \\\n",
    "           (speech['year'].astype('int32') <= 1961), 'president'] = 'Prado'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1962) & \\\n",
    "           (speech['year'].astype('int32') <= 1962), 'president'] = 'Lindley'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1963) & \\\n",
    "           (speech['year'].astype('int32') <= 1968), 'president'] = 'Belaunde'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1969) & \\\n",
    "           (speech['year'].astype('int32') <= 1975), 'president'] = 'Velasco'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1976) & \\\n",
    "           (speech['year'].astype('int32') <= 1979), 'president'] = 'Morales Bermudez'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1980) & \\\n",
    "           (speech['year'].astype('int32') <= 1984), 'president'] = 'Belaunde'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1985) & \\\n",
    "           (speech['year'].astype('int32') <= 1989), 'president'] = 'Garcia'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1990) & \\\n",
    "           (speech['year'].astype('int32') <= 2000), 'president'] = 'Fujimori'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2001) & \\\n",
    "           (speech['year'].astype('int32') <= 2005), 'president'] = 'Toledo'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2006) & \\\n",
    "           (speech['year'].astype('int32') <= 2010), 'president'] = 'Garcia'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2011) & \\\n",
    "           (speech['year'].astype('int32') <= 2015), 'president'] = 'Humala'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2016) & \\\n",
    "           (speech['year'].astype('int32') <= 2017), 'president'] = 'Kuzcynski'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2018), 'president'] = 'Vizcarra'\n",
    "\n",
    "speech['year-president'] = speech['year'] + '-' + speech['president']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>raw text</th>\n",
       "      <th>year</th>\n",
       "      <th>cleaned text</th>\n",
       "      <th>administration</th>\n",
       "      <th>president</th>\n",
       "      <th>year-president</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mensaje-1956-mpu.txt</td>\n",
       "      <td>[MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...</td>\n",
       "      <td>1956</td>\n",
       "      <td>MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...</td>\n",
       "      <td>Prado</td>\n",
       "      <td>Prado</td>\n",
       "      <td>1956-Prado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mensaje-1957-mpu.txt</td>\n",
       "      <td>[MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...</td>\n",
       "      <td>1957</td>\n",
       "      <td>MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...</td>\n",
       "      <td>Prado</td>\n",
       "      <td>Prado</td>\n",
       "      <td>1957-Prado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mensaje-1958-mpu.txt</td>\n",
       "      <td>[MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...</td>\n",
       "      <td>1958</td>\n",
       "      <td>MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...</td>\n",
       "      <td>Prado</td>\n",
       "      <td>Prado</td>\n",
       "      <td>1958-Prado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mensaje-1959-mpu.txt</td>\n",
       "      <td>[MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...</td>\n",
       "      <td>1959</td>\n",
       "      <td>MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...</td>\n",
       "      <td>Prado</td>\n",
       "      <td>Prado</td>\n",
       "      <td>1959-Prado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mensaje-1960-mpu.txt</td>\n",
       "      <td>[MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...</td>\n",
       "      <td>1960</td>\n",
       "      <td>MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...</td>\n",
       "      <td>Prado</td>\n",
       "      <td>Prado</td>\n",
       "      <td>1960-Prado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename                                           raw text  \\\n",
       "0  mensaje-1956-mpu.txt  [MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...   \n",
       "1  mensaje-1957-mpu.txt  [MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...   \n",
       "2  mensaje-1958-mpu.txt  [MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...   \n",
       "3  mensaje-1959-mpu.txt  [MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...   \n",
       "4  mensaje-1960-mpu.txt  [MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...   \n",
       "\n",
       "   year                                       cleaned text administration  \\\n",
       "0  1956  MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...          Prado   \n",
       "1  1957  MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...          Prado   \n",
       "2  1958  MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...          Prado   \n",
       "3  1959  MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...          Prado   \n",
       "4  1960  MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...          Prado   \n",
       "\n",
       "  president year-president  \n",
       "0     Prado     1956-Prado  \n",
       "1     Prado     1957-Prado  \n",
       "2     Prado     1958-Prado  \n",
       "3     Prado     1959-Prado  \n",
       "4     Prado     1960-Prado  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech['tokenized_words'] = speech['cleaned text'].apply(lambda x: clean.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we normalize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech['normalized_words'] = speech['tokenized_words'].apply(lambda x: clean.normalize_tokens(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check the most frequent words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countsDict = {}\n",
    "for word in speech['normalized_words'].sum():\n",
    "    word = word.lower()\n",
    "    if word in countsDict:\n",
    "        countsDict[word] += 1\n",
    "    else:\n",
    "        countsDict[word] = 1\n",
    "    if word in clean.STOP_WORDS:\n",
    "        print('stop word detected:', word)\n",
    "word_counts = sorted(countsDict.items(), key = lambda x : x[1], reverse = True)\n",
    "word_counts[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we tokenize sentences using the function from `nltk` for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech['tokenized_sentences'] = speech['cleaned text'].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we tokenize each word in each sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "speech['tokenized_words_in_sentences'] = speech['tokenized_sentences'].apply(lambda x: [clean.word_tokenize(s) for s in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we normalized each tokenized word within each sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech['normalized_words_in_sentences'] = speech['tokenized_words_in_sentences'].apply(lambda x: [clean.normalize_tokens(s, stop_words) for s in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
