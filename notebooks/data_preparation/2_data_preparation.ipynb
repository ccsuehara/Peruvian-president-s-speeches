{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from lucem_illud_2020 import word_tokenize\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../scripts')\n",
    "from data_cleaning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_dir = '../../data/presidentialSpeechPeru/txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mensaje-1958-mpu.txt\n",
      "mensaje-1993-af.txt\n",
      "mensaje-1972-jva.txt\n",
      "mensaje-2003-at.txt\n",
      "mensaje-2007-ag.txt\n",
      "mensaje-1966-fbt.txt\n",
      "mensaje-2018-4.txt\n",
      "mensaje-1976-fmb.txt\n",
      "mensaje-2014-oh.txt\n",
      "mensaje-1991-af.txt\n",
      "mensaje-1983-fbt.txt\n",
      "mensaje-2008-ag.txt\n",
      "mensaje-2001-at.txt\n",
      "mensaje-1997-af.txt\n",
      "mensaje-2012-oh.txt\n",
      "mensaje-1977-fmb.txt\n",
      "mensaje-1982-fbt.txt\n",
      "mensaje-1988-ag.txt\n",
      "mensaje-2019-01-vizcarra.txt\n",
      "mensaje-1985-ag.txt\n",
      "mensaje-1995-af.txt\n",
      "mensaje-1998-af.txt\n",
      "mensaje-1959-mpu.txt\n",
      "mensaje-2005-at.txt\n",
      "mensaje-1973-jva.txt\n",
      "mensaje-1987-ag.txt\n",
      "mensaje-1963-fbt.txt\n",
      "mensaje-1967-fbt.txt\n",
      "mensaje-1984-fbt.txt\n",
      "mensaje-1980-fbt.txt\n",
      "mensaje-2017-ppk.txt\n",
      "mensaje-1979-fmb.txt\n",
      "mensaje-1989-ag.txt\n",
      "mensaje-2013-oh.txt\n",
      "mensaje-1996-af.txt\n",
      "mensaje-1962-nll.txt\n",
      "mensaje-1961-mpu.txt\n",
      "mensaje-1957-mpu.txt\n",
      "mensaje-1986-ag.txt\n",
      "mensaje-2004-at.txt\n",
      "mensaje-1965-fbt.txt\n",
      "mensaje-1999-af.txt\n",
      "mensaje-1971-jva.txt\n",
      "mensaje-1975-jva.txt\n",
      "mensaje-2011-oh.txt\n",
      "mensaje-1994-af.txt\n",
      "mensaje-2002-at.txt\n",
      "mensaje-1956-mpu.txt\n",
      "mensaje-2006-ag.txt\n",
      "mensaje-2010-ag.txt\n",
      "mensaje-1968-fbt.txt\n",
      "mensaje-1992-af.txt\n",
      "mensaje-1964-fbt.txt\n",
      "mensaje-1970-jva.txt\n",
      "mensaje-1974-jva.txt\n",
      "mensaje-1981-fbt.txt\n",
      "mensaje-1978-fmb.txt\n",
      "mensaje-2009-ag.txt\n",
      "mensaje-1969-jva.txt\n",
      "mensaje-2016-ppk.txt\n",
      "mensaje-2000-af.txt\n",
      "mensaje-1990-af.txt\n",
      "mensaje-2015-oh.txt\n",
      "mensaje-1960-mpu.txt\n"
     ]
    }
   ],
   "source": [
    "speeches_raw = loadcorpus(speeches_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mensaje-1973-jva.txt\n",
      "mensaje-1961-mpu.txt\n",
      "mensaje-2013-oh.txt\n",
      "mensaje-1991-af.txt\n",
      "mensaje-2016-ppk.txt\n",
      "mensaje-2002-at.txt\n",
      "mensaje-1994-af.txt\n",
      "mensaje-2001-at.txt\n",
      "mensaje-1983-fbt.txt\n",
      "mensaje-1969-jva.txt\n",
      "mensaje-2019-01-vizcarra.txt\n",
      "mensaje-1959-mpu.txt\n",
      "mensaje-1995-af.txt\n",
      "mensaje-1971-jva.txt\n",
      "mensaje-1977-fmb.txt\n",
      "mensaje-1984-fbt.txt\n",
      "mensaje-1998-af.txt\n",
      "mensaje-1964-fbt.txt\n",
      "mensaje-1992-af.txt\n",
      "mensaje-2004-at.txt\n",
      "mensaje-2008-ag.txt\n",
      "mensaje-2012-oh.txt\n",
      "mensaje-1982-fbt.txt\n",
      "mensaje-1960-mpu.txt\n",
      "mensaje-1972-jva.txt\n",
      "mensaje-1981-fbt.txt\n",
      "mensaje-1970-jva.txt\n",
      "mensaje-2015-oh.txt\n",
      "mensaje-1975-jva.txt\n",
      "mensaje-1966-fbt.txt\n",
      "mensaje-2009-ag.txt\n",
      "mensaje-2018-4.txt\n",
      "mensaje-1978-fmb.txt\n",
      "mensaje-1993-af.txt\n",
      "mensaje-1962-nll.txt\n",
      "mensaje-2017-ppk.txt\n",
      "mensaje-2010-ag.txt\n",
      "mensaje-1968-fbt.txt\n",
      "mensaje-1996-af.txt\n",
      "mensaje-1965-fbt.txt\n",
      "mensaje-1988-ag.txt\n",
      "mensaje-1958-mpu.txt\n",
      "mensaje-1987-ag.txt\n",
      "mensaje-1979-fmb.txt\n",
      "mensaje-2007-ag.txt\n",
      "mensaje-2003-at.txt\n",
      "mensaje-1986-ag.txt\n",
      "mensaje-1974-jva.txt\n",
      "mensaje-2011-oh.txt\n",
      "mensaje-2006-ag.txt\n",
      "mensaje-2014-oh.txt\n",
      "mensaje-1990-af.txt\n",
      "mensaje-2005-at.txt\n",
      "mensaje-1957-mpu.txt\n",
      "mensaje-1963-fbt.txt\n",
      "mensaje-1989-ag.txt\n",
      "mensaje-1967-fbt.txt\n",
      "mensaje-1997-af.txt\n",
      "mensaje-2000-af.txt\n",
      "mensaje-1999-af.txt\n",
      "mensaje-1956-mpu.txt\n",
      "mensaje-1980-fbt.txt\n",
      "mensaje-1985-ag.txt\n",
      "mensaje-1976-fmb.txt\n"
     ]
    }
   ],
   "source": [
    "speech = pd.DataFrame()\n",
    "filenames = []\n",
    "raw = []\n",
    "for filename, raw_speech in speeches_raw.items():\n",
    "    print(filename)\n",
    "    filenames.append(filename)\n",
    "    raw.append(raw_speech)\n",
    "speech['filename'] = filenames\n",
    "speech['raw text'] = raw\n",
    "\n",
    "pattern = re.compile('[0-9]{4}')\n",
    "speech['year'] = speech['filename'].apply(lambda x: pattern.search(x).group(0))\n",
    "speech = speech.sort_values(by='year').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech['cleaned text'] = speech['raw text'].apply(lambda x: clean_raw_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech.loc[(speech['year'].astype('int32') >= 1956) & \\\n",
    "           (speech['year'].astype('int32') <= 1961), 'administration'] = 'Prado'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1962) & \\\n",
    "           (speech['year'].astype('int32') <= 1962), 'administration'] = 'Lindley'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1963) & \\\n",
    "           (speech['year'].astype('int32') <= 1968), 'administration'] = 'Belaunde(1)'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1969) & \\\n",
    "           (speech['year'].astype('int32') <= 1975), 'administration'] = 'Velasco'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1976) & \\\n",
    "           (speech['year'].astype('int32') <= 1979), 'administration'] = 'Morales Bermudez'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1980) & \\\n",
    "           (speech['year'].astype('int32') <= 1984), 'administration'] = 'Belaunde(2)'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1985) & \\\n",
    "           (speech['year'].astype('int32') <= 1989), 'administration'] = 'Garcia(1)'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1990) & \\\n",
    "           (speech['year'].astype('int32') <= 1994), 'administration'] = 'Fujimori(1)'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1995) & \\\n",
    "           (speech['year'].astype('int32') <= 2000), 'administration'] = 'Fujimori(2)'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2001) & \\\n",
    "           (speech['year'].astype('int32') <= 2005), 'administration'] = 'Toledo'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2006) & \\\n",
    "           (speech['year'].astype('int32') <= 2010), 'administration'] = 'Garcia(2)'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2011) & \\\n",
    "           (speech['year'].astype('int32') <= 2015), 'administration'] = 'Humala'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2016), 'administration'] = 'Kuzcynski/Vizcarra'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1956) & \\\n",
    "           (speech['year'].astype('int32') <= 1961), 'president'] = 'Prado'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1962) & \\\n",
    "           (speech['year'].astype('int32') <= 1962), 'president'] = 'Lindley'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1963) & \\\n",
    "           (speech['year'].astype('int32') <= 1968), 'president'] = 'Belaunde'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1969) & \\\n",
    "           (speech['year'].astype('int32') <= 1975), 'president'] = 'Velasco'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1976) & \\\n",
    "           (speech['year'].astype('int32') <= 1979), 'president'] = 'Morales Bermudez'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1980) & \\\n",
    "           (speech['year'].astype('int32') <= 1984), 'president'] = 'Belaunde'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1985) & \\\n",
    "           (speech['year'].astype('int32') <= 1989), 'president'] = 'Garcia'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 1990) & \\\n",
    "           (speech['year'].astype('int32') <= 2000), 'president'] = 'Fujimori'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2001) & \\\n",
    "           (speech['year'].astype('int32') <= 2005), 'president'] = 'Toledo'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2006) & \\\n",
    "           (speech['year'].astype('int32') <= 2010), 'president'] = 'Garcia'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2011) & \\\n",
    "           (speech['year'].astype('int32') <= 2015), 'president'] = 'Humala'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2016) & \\\n",
    "           (speech['year'].astype('int32') <= 2017), 'president'] = 'Kuzcynski'\n",
    "\n",
    "speech.loc[(speech['year'].astype('int32') >= 2018), 'president'] = 'Vizcarra'\n",
    "\n",
    "speech['year-president'] = speech['year'] + '-' + speech['president']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>raw text</th>\n",
       "      <th>year</th>\n",
       "      <th>cleaned text</th>\n",
       "      <th>administration</th>\n",
       "      <th>president</th>\n",
       "      <th>year-president</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mensaje-1956-mpu.txt</td>\n",
       "      <td>[MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...</td>\n",
       "      <td>1956</td>\n",
       "      <td>MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...</td>\n",
       "      <td>Prado</td>\n",
       "      <td>Prado</td>\n",
       "      <td>1956-Prado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mensaje-1957-mpu.txt</td>\n",
       "      <td>[MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...</td>\n",
       "      <td>1957</td>\n",
       "      <td>MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...</td>\n",
       "      <td>Prado</td>\n",
       "      <td>Prado</td>\n",
       "      <td>1957-Prado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mensaje-1958-mpu.txt</td>\n",
       "      <td>[MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...</td>\n",
       "      <td>1958</td>\n",
       "      <td>MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...</td>\n",
       "      <td>Prado</td>\n",
       "      <td>Prado</td>\n",
       "      <td>1958-Prado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mensaje-1959-mpu.txt</td>\n",
       "      <td>[MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...</td>\n",
       "      <td>1959</td>\n",
       "      <td>MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...</td>\n",
       "      <td>Prado</td>\n",
       "      <td>Prado</td>\n",
       "      <td>1959-Prado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mensaje-1960-mpu.txt</td>\n",
       "      <td>[MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...</td>\n",
       "      <td>1960</td>\n",
       "      <td>MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...</td>\n",
       "      <td>Prado</td>\n",
       "      <td>Prado</td>\n",
       "      <td>1960-Prado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename                                           raw text  \\\n",
       "0  mensaje-1956-mpu.txt  [MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...   \n",
       "1  mensaje-1957-mpu.txt  [MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...   \n",
       "2  mensaje-1958-mpu.txt  [MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...   \n",
       "3  mensaje-1959-mpu.txt  [MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...   \n",
       "4  mensaje-1960-mpu.txt  [MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PER...   \n",
       "\n",
       "   year                                       cleaned text administration  \\\n",
       "0  1956  MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...          Prado   \n",
       "1  1957  MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...          Prado   \n",
       "2  1958  MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...          Prado   \n",
       "3  1959  MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...          Prado   \n",
       "4  1960  MENSAJE DEL PRESIDENTE CONSTITUCIONAL DEL PERÚ...          Prado   \n",
       "\n",
       "  president year-president  \n",
       "0     Prado     1956-Prado  \n",
       "1     Prado     1957-Prado  \n",
       "2     Prado     1958-Prado  \n",
       "3     Prado     1959-Prado  \n",
       "4     Prado     1960-Prado  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech['tokenized_words'] = speech['cleaned text'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 51443),\n",
       " ('la', 27769),\n",
       " ('y', 22244),\n",
       " ('el', 19131),\n",
       " ('en', 18154),\n",
       " ('que', 17423),\n",
       " ('a', 13551),\n",
       " ('los', 11797),\n",
       " ('del', 10368),\n",
       " ('las', 7986),\n",
       " ('se', 7389),\n",
       " ('para', 6633),\n",
       " ('con', 6168),\n",
       " ('un', 5543),\n",
       " ('por', 5116),\n",
       " ('ha', 4345),\n",
       " ('una', 4317),\n",
       " ('al', 3948),\n",
       " ('no', 3317),\n",
       " ('es', 3167),\n",
       " ('su', 3012),\n",
       " ('más', 2924),\n",
       " ('como', 2427),\n",
       " ('En', 2183),\n",
       " ('país', 2135)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countsDict = {}\n",
    "for word in speech['tokenized_words'].sum():\n",
    "    if word in countsDict:\n",
    "        countsDict[word] += 1\n",
    "    else:\n",
    "        countsDict[word] = 1\n",
    "word_counts = sorted(countsDict.items(), key = lambda x : x[1], reverse = True)\n",
    "word_counts[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "for word, count in word_counts:\n",
    "    if word == 'al':\n",
    "        break\n",
    "    else:\n",
    "        stop_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_words = ['por', 'al', 'este', 'en', 'como', 'lo', 'el', 'la', 'las', 'los', 'su', 'sus'\n",
    "              'y', 'de', 'que', 'a', 'del', 'para', 'con', 'se', 'ante']\n",
    "for word in more_words:\n",
    "    stop_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech['normalized_words'] = speech['tokenized_words'].apply(lambda x: normalize_tokens(x, stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech['tokenized_sentences'] = speech['cleaned text'].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech['tokenized_words_in_sentences'] = speech['tokenized_sentences'].apply(lambda x: [word_tokenize(s) for s in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bd5468fe2262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspeech\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'normalized_words_in_sentences'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeech\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_words_in_sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnormalize_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-bd5468fe2262>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspeech\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'normalized_words_in_sentences'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeech\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_words_in_sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnormalize_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-bd5468fe2262>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspeech\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'normalized_words_in_sentences'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeech\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_words_in_sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnormalize_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/lsanmartin/Peruvian-presidents-speeches/scripts/data_cleaning.py\u001b[0m in \u001b[0;36mnormalize_tokens\u001b[0;34m(word_list, extra_stop)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#We can use a generator here as we just need to iterate over it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mnormalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'es'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mword_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# in data dir / shortcut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# installed as package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_link\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE051\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/spacy/data/es/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_init_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, **overrides)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE052\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath2str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, **overrides)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(self, path, exclude, disable)\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0;31m# Convert to list here in case exclude is (default) tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0mexclude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserializers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(path, readers, exclude)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;31m# Split to support file names like meta.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0mdeserializers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"meta.json\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrsly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m         deserializers[\"vocab\"] = lambda p: self.vocab.from_disk(\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         ) and _fix_pretrained_vectors_name(self)\n\u001b[1;32m    927\u001b[0m         deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(\n",
      "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.from_disk\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/spacy/lookups.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/spacy/lookups.py\u001b[0m in \u001b[0;36mfrom_bytes\u001b[0;34m(self, bytes_data, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msrsly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsgpack_loads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/spacy/lookups.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \"\"\"Set new key/value pair. String keys will be hashed.\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "speech['normalized_words_in_sentences'] = speech['tokenized_words_in_sentences'].apply(lambda x: [normalize_tokens(s, stop_words) for s in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech.to_pickle('../../data/clean/speech.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
